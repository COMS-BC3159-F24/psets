{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xTKiGPkJ5qRy"
   },
   "source": [
    "# PSET 1: Optimizing Matrix Multiplication & CUDA\n",
    "\n",
    "...\n",
    "\n",
    "Try not to add additional cells nor rearrange any that exist now as it will mess with our autograder (but feel free to open another Colab/notebook on the side).  \n",
    "\n",
    "**Note:** the autograder on Gradescope might take a while (~5+ min) to run (the benchmarking exercises at the end slow things down, feel free to comment them all out).  The CUDA exercises will be graded run manually.\n",
    "\n",
    "### Make sure to submit your final notebook with all of your solutions to Gradescope!\n",
    "[Direct Gradescope Link](https://www.gradescope.com/courses/820552)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TOusEnXk5qRz"
   },
   "source": [
    "### Before Starting\n",
    "\n",
    "This problem set uses NVCC (NVIDIA CUDA Compiler) within Google Colab to compile and run CUDA code. Google Colab provides a convenient (and free!) environment with GPU support for executing these programs.  At the top right corner, under the arrow dropdown next to the `Connect` button, select \"Change runtime type\" and choose `T4 GPU` for this problem set.  Note, across your account, you can only have one runtime connected to a GPU at a given time.\n",
    "\n",
    "We're in an interactive _Python_ notebook.  So, of course, running C++ code is not going to be as easy as it is to run Python code.  That said, we'll once again use helpers to make this cleaner.\n",
    "\n",
    "Our plugins `%%cpurun` and `%%gpurun` save, compile, and run your C++ and/or CUDA code in the cell.  This is different than before where the helper simply *saved* the file, and then we would compile using `g++` and run it ourselves.  But now, since you remember the nuances of working with a compiled language, we'll just bundle it all up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_t8fU8-85qR0",
    "outputId": "0179e509-7fc2-4896-fbdd-21ea0265cf78"
   },
   "outputs": [],
   "source": [
    "# make sure CUDA is installed\n",
    "!nvcc --version\n",
    "\n",
    "# make sure you have a GPU runtime (if this fails go to runtime -> change runtime type)\n",
    "!nvidia-smi\n",
    "\n",
    "# Install some magic to run and save .cpp programs\n",
    "!curl -o ./cpu_runner.py https://raw.githubusercontent.com/COMS-BC3159-F24/helpers/main/cpu_runner.py\n",
    "%load_ext cpu_runner\n",
    "\n",
    "# Install some magic to run and save .cu C++ CUDA programs\n",
    "!curl -o ./gpu_runner.py https://raw.githubusercontent.com/COMS-BC3159-F24/helpers/main/gpu_runner.py\n",
    "%load_ext gpu_runner\n",
    "\n",
    "# to learn about how to do more fancy things with CUDA using this API see:\n",
    "# https://nvcc4jupyter.readthedocs.io/en/latest/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7RA3QY-a5MMj"
   },
   "source": [
    "One other note: we import a few `.o` \"dot-oh\" object and `.h` header files to bring along some printing utilities and fuzz-testing in an obscured way (we wouldn't want to give away the solutions ðŸ˜›).\n",
    "\n",
    "As you step away and return to this problem set, you will often find that Colab has disconnected your runtime and deleted any files.  You'll need to re-run cells like the above which import the magic compilation utilities as well as the cells with `curl` imports of the various `.o` and `.h` files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "3KsZoHydPptM"
   },
   "source": [
    "## Problem 1: Python Matrix Multiply (again)\n",
    "In the last problem set, you explored how to write a simple matrix multiplication in Python using a naÃ¯ve implementation for representing matrices using lists of lists.\n",
    "\n",
    "In `C++` there are ways to mimic this style:\n",
    "- multi-dimensional arrays like `int my_matrix[N][M]`\n",
    "- `std::vector<std::vector<float> >`\n",
    "\n",
    "But it gets quite a bit more difficult when we try to do this using CUDA.  An easier way to handle such a problem is to put everything into one contiguous chunk of memory in an organized way.  As we've discussed in class, there are two standard methods for representing/organizing our matrix in memory:\n",
    "1. row-major order\n",
    "2. column-major order\n",
    "\n",
    "These are visualized below:\n",
    "![row-major](https://raw.githubusercontent.com/COMS-BC3159-F24/image_assets/main/row-col-major.png)\n",
    "\n",
    "In the written part of PS0, you reacquainted yourself with the standard matrix multiplication algorithm:\n",
    "$$C_{ij} = \\sum_{k=1}^{n} A_{ik} \\times B_{kj}$$\n",
    "\n",
    "Then, in the coding part of PS0, using `list`s of `list`s, you computed the product of a matrix $A$ (in gray) which is $4\\times5$ and $B$ (blue) of dimensions $5\\times4$ whose product results in $C$ (purple) of size $4\\times4$.\n",
    "\n",
    "![matrix mult example](https://raw.githubusercontent.com/COMS-BC3159-F24/image_assets/main/matmul_example.png)\n",
    "\n",
    "This time, write a matrix multiplication implementation that indexes into provided **row-major order** matrices to compute their product.  As before, we've provided the matrices (note: they're _not_ `list`s of `list`s this time; instead, just one flat `list`) and some printing functions (albeit a bit obscured to leave the challenge of figuring out the indexing for the actual multiplication up to you)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XiEPB2MzSaG3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Helper function to print a matrix represented as a flat list in a row-major order\n",
    "def printFlatMatrix(matrix, num_rows, num_cols, width=6):\n",
    "    for i in range(num_rows):\n",
    "        formatted_row = ''.join(f'{matrix[j]:{width}}'\n",
    "                                for j in range(\n",
    "                                    i * num_cols, i * num_cols + num_cols))\n",
    "        print(formatted_row)\n",
    "\n",
    "# Matrices' dimensions (can't be inferred from list len)\n",
    "rows_A, cols_A = 4, 5\n",
    "rows_B, cols_B = 5, 4\n",
    "\n",
    "# Note: single list in row-major\n",
    "A = [\n",
    "    0, 1, 2, 3, 4,\n",
    "    5, 6, 7, 8, 9,\n",
    "    10, 11, 12, 13, 14,\n",
    "    15, 16, 17, 18, 19\n",
    "]\n",
    "B = [\n",
    "    20, 21, 22, 23,\n",
    "    24, 25, 26, 27,\n",
    "    28, 29, 30, 31,\n",
    "    32, 33, 34, 35,\n",
    "    36, 37, 38, 39\n",
    "]\n",
    "C = [0] * (rows_A * cols_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o5_tkH0ze3PI",
    "outputId": "93803217-8cfe-41dd-99f6-3a1111c7ff50",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def matrixMultiply(A, B, rows_A, cols_B):\n",
    "    ...\n",
    "    return C\n",
    "\n",
    "C = matrixMultiply(A, B, rows_A, cols_B)\n",
    "printFlatMatrix(C, rows_A, cols_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fOGWH32UV5IJ"
   },
   "source": [
    "## C++ Malloc Practice [Ungraded]\n",
    "As a warmup, let's review how we allocate memory dynamically.  Allocate memory for a row of 5 integers and fill the row with values 0-4.  Print the array, and don't forget to `free()` when you're done!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZdVkicCzV4w1",
    "outputId": "21d918c7-adc9-4368-9bd8-8c61cf5f6148"
   },
   "outputs": [],
   "source": [
    "%%cpurun -n malloc_example.cpp\n",
    "#include <cstdio>  // For printf\n",
    "#include <cstdlib> // For malloc and free\n",
    "\n",
    "int main() {\n",
    "    // Allocate memory for a row of 5 integers\n",
    "    int* rowA = nullptr; // TODO: Actually allocate!\n",
    "    if (rowA == nullptr) {\n",
    "        std::fprintf(stderr, \"Memory allocation failed\\n\");\n",
    "        return 1;  // Exit with an error code\n",
    "    }\n",
    "\n",
    "    // Fill the array with values\n",
    "    for (int i = 0; i < 5; i++) {\n",
    "        rowA[i] = i;\n",
    "    }\n",
    "\n",
    "    // Alternative way to fill the array\n",
    "    int* temp = rowA;\n",
    "    for (int i = 0; i < 5; i++) {\n",
    "        *temp = i;\n",
    "        temp++; // Pointer arithmetic, increments temp pointer raw value by sizeof(int) each time!\n",
    "    }\n",
    "\n",
    "    // Print each element of the array using printf\n",
    "    printf(\"Elements of rowA:\\n\");\n",
    "    for (int i = 0; i < 5; i++) {\n",
    "        printf(\"%d \", rowA[i]);\n",
    "    }\n",
    "    printf(\"\\n\");\n",
    "\n",
    "    // Free allocated memory\n",
    "    free(rowA);\n",
    "\n",
    "    return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "22sJblztYbyx"
   },
   "source": [
    "## Problem 2: C++ Matrix Multiply\n",
    "\n",
    "Before we jump to a CUDA implementation, let's continue warming up the background necessary by writing a `C++` implementation of matrix multiplication.\n",
    "\n",
    "Although this could be done easily using `std::vector`s of `std::vector`s or multi-dimensional arrays, let's practice allocating just **one** contiguous chunk of memory per each of our matrices and use row-major ordering to organize each matrix in memory.\n",
    "\n",
    "We've provided a `print_int_matrix()` function in the `matrix_lib.h` header.  It assumes row-major order in one contiguous chunk of memory as described above.  The function signature looks as follows:\n",
    "```c\n",
    "void print_int_matrix(const int* matrix, int num_rows, int num_cols)\n",
    "```\n",
    "\n",
    "We link the provided `matrix_lib.o` file via the magic `%%cpurun` compilation command. (It's obscured in this way so that we don't take the fun out of figuring out the indexing for your matrices!)\n",
    "\n",
    "This time all the fun is left to you!  \n",
    "1. Allocate the chunks of memory for $A$, $B$, and $C$.\n",
    "2. Fill in $A$ and $B$ matrices as shown in the image above and the Python exercise in Problem 1.\n",
    "3. Write the multiply!  (And print only $C$ via the `print_int_matrix()` function provided.)\n",
    "\n",
    "Your output should look exactly as follows:\n",
    "```text\n",
    "  320   330   340   350\n",
    " 1020  1055  1090  1125\n",
    " 1720  1780  1840  1900\n",
    " 2420  2505  2590  2675\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xESOno7gmqnl",
    "outputId": "bf2a6cb2-8ad6-448a-c7d8-03a495ef3967",
    "tags": []
   },
   "outputs": [],
   "source": [
    "!curl -o ./matrix_lib.o https://raw.githubusercontent.com/COMS-BC3159-F24/helpers/main/matrix_lib.o\n",
    "!curl -o ./matrix_lib.h https://raw.githubusercontent.com/COMS-BC3159-F24/helpers/main/matrix_lib.h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XMbw1tAiYbOD",
    "outputId": "91780820-d163-48b3-d765-04cc850fe445",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%cpurun -n cpp_int_matmul.cpp -o matrix_lib.o\n",
    "#include <cstdio>\n",
    "#include <cstdlib>\n",
    "#include \"matrix_lib.h\"\n",
    "\n",
    "// TODO: Write your matrix multiplication\n",
    "//       where A: MxN, B: NxP, C: MxP\n",
    "//       and you write C in place\n",
    "void matrixMultiplyCPU_int(int* A, int* B, int* C, int M, int N, int P) {\n",
    "...\n",
    "...\n",
    "...\n",
    "...\n",
    "...\n",
    "...\n",
    "...\n",
    "...\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "int main() {\n",
    "    const int rows_A = 4, cols_A = 5;\n",
    "    const int rows_B = 5, cols_B = 4;\n",
    "    const int rows_C = rows_A, cols_C = cols_B;\n",
    "\n",
    "    // Allocate matrix A\n",
    "    int* A = nullptr; // TODO!\n",
    "    ...\n",
    "    if (A == nullptr) {\n",
    "        fprintf(stderr, \"Memory allocation for A failed\\n\");\n",
    "        return 1;\n",
    "    }\n",
    "\n",
    "    // Fill matrix A (use print function to temporarily help initialize)\n",
    "    ...\n",
    "    ...\n",
    "    ...\n",
    "    ...\n",
    "    ...\n",
    "\n",
    "    // Allocate matrix B\n",
    "    int* B = nullptr; // TODO!\n",
    "    ...\n",
    "    if (B == nullptr) {\n",
    "        fprintf(stderr, \"Memory allocation for B failed\\n\");\n",
    "        ...\n",
    "        return 1;\n",
    "    }\n",
    "\n",
    "    // Fill matrix B\n",
    "    ...\n",
    "    ...\n",
    "    ...\n",
    "    ...\n",
    "    ...\n",
    "\n",
    "    // Allocate matrix C (result matrix)\n",
    "    int* C = nullptr; // TODO!\n",
    "    ...\n",
    "    if (C == nullptr) {\n",
    "        fprintf(stderr, \"Memory allocation for C failed\\n\");\n",
    "        ...\n",
    "        ...\n",
    "        return 1;\n",
    "    }\n",
    "\n",
    "    // Perform matrix multiplication\n",
    "    matrixMultiplyCPU_int(A, B, C, rows_A, cols_A, cols_B);\n",
    "\n",
    "    // Print result\n",
    "    print_int_matrix(C, rows_A, cols_B);\n",
    "\n",
    "    // Free allocated memory\n",
    "    ...\n",
    "    ...\n",
    "    ...\n",
    "\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "RZY2NDYlXOhy"
   },
   "source": [
    "## Problem 3: Float Matrix Multiply in C++\n",
    "\n",
    "Before moving forward, let's run this exercise again, but using `float` instead of `int`.  In the same header, we've provided a `print_float_matrix()` for you to use (which prints 2 decimals of precision).  Your output should look exactly as follows:\n",
    "```text\n",
    " 320.00  330.00  340.00  350.00\n",
    "1020.00 1055.00 1090.00 1125.00\n",
    "1720.00 1780.00 1840.00 1900.00\n",
    "2420.00 2505.00 2590.00 2675.00\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!curl -o ./matrix_lib.o https://raw.githubusercontent.com/COMS-BC3159-F24/helpers/main/matrix_lib.o\n",
    "!curl -o ./matrix_lib.h https://raw.githubusercontent.com/COMS-BC3159-F24/helpers/main/matrix_lib.h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tZWlxWOWfB28",
    "outputId": "cd3551d5-36c9-4e40-99c4-d8613b74fb3a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%cpurun -n cpp_float_matmul.cpp -o matrix_lib.o\n",
    "#include <cstdio>\n",
    "#include <cstdlib>\n",
    "#include \"matrix_lib.h\"\n",
    "\n",
    "// TODO: Write your matrix multiplication\n",
    "//       where A: MxN, B: NxP, C: MxP\n",
    "//       and you write C in place\n",
    "void matrixMultiplyCPU_float(float* A, float* B, float* C, int M, int N, int P) {\n",
    "...\n",
    "...\n",
    "...\n",
    "...\n",
    "...\n",
    "...\n",
    "...\n",
    "...\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "int main() {\n",
    "    const int rows_A = 4, cols_A = 5;\n",
    "    const int rows_B = 5, cols_B = 4;\n",
    "    const int rows_C = rows_A, cols_C = cols_B;\n",
    "\n",
    "    // Allocate matrix A\n",
    "    float* A = nullptr; // TODO!\n",
    "    ...\n",
    "    if (A == nullptr) {\n",
    "        fprintf(stderr, \"Memory allocation for A failed\\n\");\n",
    "        return 1;\n",
    "    }\n",
    "\n",
    "    // Fill matrix A (use print function to temporarily help initialize)\n",
    "    ...\n",
    "    ...\n",
    "    ...\n",
    "    ...\n",
    "    ...\n",
    "\n",
    "    // Allocate matrix B\n",
    "    float* B = nullptr; // TODO!\n",
    "    ...\n",
    "    if (B == nullptr) {\n",
    "        fprintf(stderr, \"Memory allocation for B failed\\n\");\n",
    "        ...\n",
    "        return 1;\n",
    "    }\n",
    "\n",
    "    // Fill matrix B\n",
    "    ...\n",
    "    ...\n",
    "    ...\n",
    "    ...\n",
    "    ...\n",
    "\n",
    "    // Allocate matrix C (result matrix)\n",
    "    float* C = nullptr; // TODO!\n",
    "    ...\n",
    "    if (C == nullptr) {\n",
    "        fprintf(stderr, \"Memory allocation for C failed\\n\");\n",
    "        ...\n",
    "        ...\n",
    "        return 1;\n",
    "    }\n",
    "\n",
    "    // Perform matrix multiplication\n",
    "    matrixMultiplyCPU_float(A, B, C, rows_A, cols_A, cols_B);\n",
    "\n",
    "    // Print result\n",
    "    print_float_matrix(C, rows_A, cols_B);\n",
    "\n",
    "    // Free allocated memory\n",
    "    ...\n",
    "    ...\n",
    "    ...\n",
    "\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "01CiKzE88hF-"
   },
   "source": [
    "Let's put it to the test!  Beyond our simple example, we provide a fuzz test (against our reference `C++` implementation) to help you validate your implementation is working as expected!  All you need to do is paste in your `matrixMultiplyCPU_float()` implementation and run!\n",
    "\n",
    "First, we'll import our object/header."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "editable": false,
    "id": "SaCLLC_Y8q6I",
    "outputId": "e8ffc7d8-d983-419a-de40-df9dfc70c52c"
   },
   "outputs": [],
   "source": [
    "!curl -o ./cpu_fuzz_test.o https://raw.githubusercontent.com/COMS-BC3159-F24/helpers/main/cpu_fuzz_test.o\n",
    "!curl -o ./cpu_fuzz_test.h https://raw.githubusercontent.com/COMS-BC3159-F24/helpers/main/cpu_fuzz_test.h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "editable": false,
    "id": "nDn_Ek0_-hbd",
    "outputId": "25c2f65e-9465-4e13-97aa-cb78a2c1cba4"
   },
   "outputs": [],
   "source": [
    "%%cpurun -n student_testing.cpp -o matrix_lib.o,cpu_fuzz_test.o\n",
    "#include \"matrix_lib.h\"\n",
    "#include \"cpu_fuzz_test.h\"\n",
    "\n",
    "// Student implementation of CUDA matrix multiplication\n",
    "void matrixMultiplyCPU_float(float* A, float* B, float* C, int M, int N, int P) {\n",
    "    ...\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    fuzzTestMatrixMultiplication(10, 50);  // Run fuzz tests\n",
    "    return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "JCTgNkzz5qR3"
   },
   "source": [
    "## CUDA Compiling Basics [Ungraded]\n",
    "Print the following by writing a `__global__` kernel and invoking it.\n",
    "```text\n",
    "Hello from the GPU!\n",
    "```\n",
    "We'll add a `cudaDeviceSynchronize` at the end of your `main()` function to wrap up neatly!  Recall what happens if you don't include that line...(and if you don't remember, then try commenting it out)!\n",
    "\n",
    "#### Not seeing any output?  Did you remember to change your runtime?\n",
    "Don't forget to change your runtime in Google Colab to a T4 GPU.\n",
    "\n",
    "![change runtime](https://raw.githubusercontent.com/COMS-BC3159-F24/image_assets/main/changeruntime.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rEF6uOInU7AA",
    "outputId": "99f503ee-b320-4f2f-bc9b-f05131cba121"
   },
   "outputs": [],
   "source": [
    "%%gpurun -n my_kernel.cu\n",
    "#include <cstdio>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "// This function runs on the GPU\n",
    "__global__ void helloWorldKernel() {\n",
    "    printf(\"Hello World!\\n\");\n",
    "}\n",
    "\n",
    "// This function runs on the CPU\n",
    "__host__\n",
    "int main() {\n",
    "    // Launch the kernel on the GPU\n",
    "    helloWorldKernel<<<1, 1>>>();\n",
    "\n",
    "    // Wait for the kernel to finish executing\n",
    "    cudaDeviceSynchronize();\n",
    "\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "SKChlkVAggQB"
   },
   "source": [
    "## Problem 4: CUDA Matrix Multiply\n",
    "The time has finally arrived...to \"CUDA-fy\" your matrix multiplication code.  You've practiced examples in class and in our HelloCUDA exercises.  Now, let's do the necessary allocations, write a kernel, move and copy data, and run!\n",
    "\n",
    "To constrain your solution, let's use a 2D block of dimensions 2x2.  Yes, this is tiny.  Something more standard like 32 to collect the threads in a warp is typically sensible for larger matrices.  But we have a small output matrix, and this is a first exercise, so let's keep things simple for now.  (As a follow-on exercise, you could try tiling your matrix and finding ways to leverage shared memory in smarter ways.)\n",
    "\n",
    "You'll need to make sure your grid and respective grid dimensions support the whole matrix.  Your kernel should compute **one** element of the resulting $C$ matrix.  (We have so much compute available, so let's go parallel heavy!)\n",
    "\n",
    "Your code from the `C++` \"CPU\" version of matrix multiply in Problem 3 can be used as a starting point here.  In fact, to make checking things easy, we have provided a framework of a script that leverages your `matrixMultiplyCPU_float()` from Problem 3 (just paste it here) for a reference comparison.\n",
    "\n",
    "Follow each step provided in the \"comments\" `// TODO`, etc. and we've already included the print statements (using our helpers from `#include \"matrix_lib.h\"` again) that should provide the exact output we expect:\n",
    "\n",
    "```text\n",
    "CPU Matrix Multiply:\n",
    " 320.00  330.00  340.00  350.00\n",
    "1020.00 1055.00 1090.00 1125.00\n",
    "1720.00 1780.00 1840.00 1900.00\n",
    "2420.00 2505.00 2590.00 2675.00\n",
    "\n",
    "GPU Matrix Multiply:\n",
    " 320.00  330.00  340.00  350.00\n",
    "1020.00 1055.00 1090.00 1125.00\n",
    "1720.00 1780.00 1840.00 1900.00\n",
    "2420.00 2505.00 2590.00 2675.00\n",
    "\n",
    "Matrices match!\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!curl -o ./matrix_lib.o https://raw.githubusercontent.com/COMS-BC3159-F24/helpers/main/matrix_lib.o\n",
    "!curl -o ./matrix_lib.h https://raw.githubusercontent.com/COMS-BC3159-F24/helpers/main/matrix_lib.h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qqtWMxOc5qR3",
    "outputId": "fa2b56b2-7635-498e-91a5-59659fa038c8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%gpurun -n cuda_matmul.cu -o matrix_lib.o\n",
    "#include <iostream>\n",
    "#include <cmath>\n",
    "#include <cuda_runtime.h>\n",
    "#include \"matrix_lib.h\"\n",
    "\n",
    "// Paste your Problem 3 solution for comparison\n",
    "void matrixMultiplyCPU_float(float* A, float* B, float* C, int M, int N, int P) {\n",
    "...\n",
    "...\n",
    "...\n",
    "...\n",
    "...\n",
    "...\n",
    "...\n",
    "...\n",
    "}\n",
    "\n",
    "// CUDA kernel to multiply two matrices A[M][N] * B[N][P] = C[M][P]\n",
    "// Specify what work to complete via threadIdx, blockIdx, blockDim\n",
    "// Compute one element of the resulting matrix\n",
    "__global__ void matrixMultiplyCUDA(float* A, float* B, float* C, int M, int N, int P) {\n",
    "    ...\n",
    "    ...\n",
    "    ...\n",
    "    ...\n",
    "    ...\n",
    "    ...\n",
    "    ...\n",
    "    ...\n",
    "    ...\n",
    "    ...\n",
    "}\n",
    "\n",
    "// Compare matrices represented as flat arrays with single loop\n",
    "// Allow for some floating-point error (GPU and CPU may differ slightly)\n",
    "bool compareMatrices(const float* A, const float* B, int total_elements) {\n",
    "    float epsilon = 0.001f; // Tolerance for floating-point comparison\n",
    "    int precision_issues = 0;\n",
    "\n",
    "    // Note: not traversing in row-major order\n",
    "    for (int i = 0; i < total_elements; ++i) {\n",
    "        float diff = fabs(A[i] - B[i]);\n",
    "        if (diff > epsilon) {\n",
    "            printf(\"Matrices differ at element %d: A[%d] = %f, B[%d] = %f\\n\", i, i, A[i], i, B[i]);\n",
    "            return false;\n",
    "        } else if (diff > epsilon / 10 && diff <= epsilon) {\n",
    "            precision_issues++;\n",
    "        }\n",
    "    }\n",
    "\n",
    "    if (precision_issues > 0) {\n",
    "        fprintf(stderr, \"Warning: %d elements had values close to the precision threshold.\\n\", precision_issues);\n",
    "    }\n",
    "\n",
    "    return true;\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    const int rows_A = 4, cols_A = 5;\n",
    "    const int rows_B = 5, cols_B = 4;\n",
    "    const int rows_C = rows_A, cols_C = cols_B;\n",
    "\n",
    "    // Allocate memory for matrices A, B, C\n",
    "    // * C_gpu will be for copying and comparison purposes\n",
    "    float* h_A = nullptr; // TODO\n",
    "    ...\n",
    "    float* h_B = nullptr; // TODO\n",
    "    ...\n",
    "    float* h_C_cpu = nullptr; // TODO\n",
    "    ...\n",
    "    float* h_C_gpu = nullptr;\n",
    "    ...\n",
    "\n",
    "    // Fill matrix A and B (similar to as you did in the CPU version)\n",
    "    ...\n",
    "    ...\n",
    "    ...\n",
    "    ...\n",
    "    ...\n",
    "    ...\n",
    "    ...\n",
    "    ...\n",
    "    ...\n",
    "    ...\n",
    "\n",
    "    // Perform matrix multiplication on CPU (C++)\n",
    "    matrixMultiplyCPU_float(h_A, h_B, h_C_cpu, rows_A, cols_A, cols_B);\n",
    "    printf(\"CPU Matrix Multiply:\\n\");\n",
    "    print_float_matrix(h_C_cpu, rows_C, cols_C);\n",
    "\n",
    "    // Perform matrix multiplication on GPU (CUDA)\n",
    "    // create d_ device pointers, allocate GPU memory, and fill the memory\n",
    "    float *d_A, *d_B, *d_C;\n",
    "    ...\n",
    "    ...\n",
    "    ...\n",
    "    ...\n",
    "    ...\n",
    "\n",
    "    // Define grid/block dimensions, then launch the kernel\n",
    "    ...\n",
    "    ...\n",
    "    ...\n",
    "\n",
    "    // Copy result back to host (h_C_gpu) for comparison\n",
    "    ...\n",
    "\n",
    "    printf(\"\\nGPU Matrix Multiply:\\n\");\n",
    "    print_float_matrix(h_C_gpu, rows_C, cols_B);\n",
    "\n",
    "    // Compare the CPU and GPU results\n",
    "    if (compareMatrices(h_C_cpu, h_C_gpu, rows_C*cols_C)) {\n",
    "        printf(\"\\nMatrices match!\\n\");\n",
    "    } else {\n",
    "        printf(\"\\nMatrices do NOT match.\\n\");\n",
    "    }\n",
    "\n",
    "    // Free memory\n",
    "    ...\n",
    "    ...\n",
    "    ...\n",
    "    ...\n",
    "    ...\n",
    "    ...\n",
    "    ...\n",
    "\n",
    "    return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "WBT8Rf-s7-7r"
   },
   "source": [
    "Let's put it to the test!  Beyond our simple example, we provide a fuzz test (against our reference `C++` implementation) to help you validate your implementation is working as expected!  All you need to do is paste in your CUDA kernel and run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "editable": false,
    "id": "AfV7Zyig3RNF",
    "outputId": "920b9234-ecb3-4b55-8e41-8919d64172ba"
   },
   "outputs": [],
   "source": [
    "!curl -o ./fuzz_test.o https://raw.githubusercontent.com/COMS-BC3159-F24/helpers/main/fuzz_test.o\n",
    "!curl -o ./fuzz_test.h https://raw.githubusercontent.com/COMS-BC3159-F24/helpers/main/fuzz_test.h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "editable": false,
    "id": "NXNBPozFwcRt",
    "outputId": "dee451ae-e729-4f1b-adb1-eda427311b8f"
   },
   "outputs": [],
   "source": [
    "%%gpurun -n student_cuda_testing.cu -o matrix_lib.o,fuzz_test.o\n",
    "#include \"matrix_lib.h\"\n",
    "#include \"fuzz_test.h\"\n",
    "\n",
    "// Your CUDA matrix multiplication kernel (one element of C per thread)\n",
    "__global__ void matrixMultiplyCUDA(float* A, float* B, float* C, int M, int N, int P) {\n",
    "    ...\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    fuzzTestMatrixMultiplication(10, 50);  // Run fuzz tests\n",
    "    cudaDeviceSynchronize();\n",
    "    return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Problem 5: One More Time!  (CUDA Large)\n",
    "Now, let's do another matrix multiplication leveraging much of the same code you used before.  This time, we'll use a 2D block of dimensions 32x32.  You'll need to make sure your grid dimensions use enough blocks to cover the entire matrix.\n",
    "\n",
    "Again, your kernel should compute **one** element of the resulting $C$ matrix via each thread.\n",
    "\n",
    "Your code from the `C++` \"CPU\" version of matrix multiply in Problem 3 will be used as reference here, again.  We have provided the same framework of a script that leverages your `matrixMultiplyCPU_float()` from Problem 3 (just paste it here) for a reference comparison.\n",
    "\n",
    "This time, we provide the functions to \"fill in\" your matrices with a specified pattern of 1s and 0s.\n",
    "\n",
    "Follow each step provided in the \"comments\" `// TODO`, etc. and we've already included the print statements (using our helpers from `#include \"matrix_lib.h\"` again) that should provide the exact output we expect:\n",
    "\n",
    "```text\n",
    "CPU Matrix Multiply:\n",
    "1000.00    0.00 1000.00    0.00\n",
    "   0.00    0.00    0.00    0.00\n",
    "...\n",
    "\n",
    "GPU Matrix Multiply:\n",
    "1000.00    0.00 1000.00    0.00\n",
    "   0.00    0.00    0.00    0.00\n",
    "...\n",
    "\n",
    "Matrices match!\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!curl -o ./matrix_lib.o https://raw.githubusercontent.com/COMS-BC3159-F24/helpers/main/matrix_lib.o\n",
    "!curl -o ./matrix_lib.h https://raw.githubusercontent.com/COMS-BC3159-F24/helpers/main/matrix_lib.h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%gpurun -n big_cuda.cu -o matrix_lib.o\n",
    "#include <iostream>\n",
    "#include <cmath>\n",
    "#include <cuda_runtime.h>\n",
    "#include \"matrix_lib.h\"\n",
    "\n",
    "// Paste your Problem 3 solution for comparison\n",
    "void matrixMultiplyCPU_float(float* A, float* B, float* C, int M, int N, int P) {\n",
    "...\n",
    "...\n",
    "...\n",
    "...\n",
    "...\n",
    "...\n",
    "...\n",
    "...\n",
    "}\n",
    "\n",
    "// CUDA kernel to multiply two matrices A[M][N] * B[N][P] = C[M][P]\n",
    "// Specify what work to complete via threadIdx, blockIdx, blockDim\n",
    "// Compute one element of the resulting matrix\n",
    "__global__ void matrixMultiplyCUDA(float* A, float* B, float* C, int M, int N, int P) {\n",
    "    ...\n",
    "    ...\n",
    "    ...\n",
    "    ...\n",
    "    ...\n",
    "    ...\n",
    "    ...\n",
    "    ...\n",
    "    ...\n",
    "    ...\n",
    "}\n",
    "\n",
    "// Compare matrices represented as flat arrays with single loop\n",
    "// Allow for some floating-point error (GPU and CPU may differ slightly)\n",
    "bool compareMatrices(const float* A, const float* B, int total_elements) {\n",
    "    float epsilon = 0.001f; // Tolerance for floating-point comparison\n",
    "    int precision_issues = 0;\n",
    "\n",
    "    // Note: not traversing in row-major order\n",
    "    for (int i = 0; i < total_elements; ++i) {\n",
    "        float diff = fabs(A[i] - B[i]);\n",
    "        if (diff > epsilon) {\n",
    "            printf(\"Matrices differ at element %d: A[%d] = %f, B[%d] = %f\\n\", i, i, A[i], i, B[i]);\n",
    "            return false;\n",
    "        } else if (diff > epsilon / 10 && diff <= epsilon) {\n",
    "            precision_issues++;\n",
    "        }\n",
    "    }\n",
    "\n",
    "    if (precision_issues > 0) {\n",
    "        fprintf(stderr, \"Warning: %d elements had values close to the precision threshold.\\n\", precision_issues);\n",
    "    }\n",
    "\n",
    "    return true;\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    const int rows_A = 2000, cols_A = 2000;\n",
    "    const int rows_B = 2000, cols_B = 2000;\n",
    "    const int rows_C = rows_A, cols_C = cols_B;\n",
    "\n",
    "    // Allocate memory for matrices A, B, C\n",
    "    // * C_gpu will be for copying and comparison purposes\n",
    "    float* h_A = nullptr; // TODO\n",
    "    ...\n",
    "    float* h_B = nullptr; // TODO\n",
    "    ...\n",
    "    float* h_C_cpu = nullptr; // TODO\n",
    "    ...\n",
    "    float* h_C_gpu = nullptr;\n",
    "    ...\n",
    "\n",
    "    // Fill matrix A with alternating 0 and 1 in a checkerboard pattern\n",
    "    for (int idx = 0; idx < rows_A * cols_A; ++idx) {\n",
    "        h_A[idx] = ((idx / cols_A + idx % cols_A) % 2 == 0) ? 1.0f : 0.0f;  // Checkerboard pattern\n",
    "    }\n",
    "\n",
    "    // Fill matrix B with alternating 0 and 1 in a different pattern\n",
    "    for (int idx = 0; idx < rows_B * cols_B; ++idx) {\n",
    "        h_B[idx] = (((idx / cols_B) % 2 == 0) && ((idx % cols_B) % 2 == 0)) ? 1.0f : 0.0f;\n",
    "    }\n",
    "\n",
    "    // Perform matrix multiplication on CPU (C++)\n",
    "    matrixMultiplyCPU_float(h_A, h_B, h_C_cpu, rows_A, cols_A, cols_B);\n",
    "    printf(\"CPU Matrix Multiply:\\n\");\n",
    "    print_float_matrix(h_C_cpu, rows_C, cols_C);\n",
    "\n",
    "    // Perform matrix multiplication on GPU (CUDA)\n",
    "    // create d_ device pointers, allocate GPU memory, and fill the memory\n",
    "    float *d_A, *d_B, *d_C;\n",
    "    ...\n",
    "    ...\n",
    "    ...\n",
    "    ...\n",
    "    ...\n",
    "\n",
    "    // Define grid/block dimensions, then launch the kernel\n",
    "    ...\n",
    "    ...\n",
    "    ...\n",
    "\n",
    "    // Copy result back to host (h_C_gpu) for comparison\n",
    "    ...\n",
    "\n",
    "    printf(\"\\nGPU Matrix Multiply:\\n\");\n",
    "    print_float_matrix(h_C_gpu, rows_C, cols_B);\n",
    "\n",
    "    // Compare the CPU and GPU results\n",
    "    if (compareMatrices(h_C_cpu, h_C_gpu, rows_C*cols_C)) {\n",
    "        printf(\"\\nMatrices match!\\n\");\n",
    "    } else {\n",
    "        printf(\"\\nMatrices do NOT match.\\n\");\n",
    "    }\n",
    "\n",
    "    // Free memory\n",
    "    ...\n",
    "    ...\n",
    "    ...\n",
    "    ...\n",
    "    ...\n",
    "    ...\n",
    "    ...\n",
    "\n",
    "    return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XlO97io3_NYs"
   },
   "source": [
    "---\n",
    "\n",
    "## Benchmarking! [Ungraded]\n",
    "Nice!  Now that you're done with the \"work\" for this PSET, we want to start adding some runtime numbers to this whole \"optimization\" concept.\n",
    "\n",
    "In class, and more widely, we've discussed the slowness of Python *v.* C (an interpreted versus compiled language).  We've talked about the systems effects of cache and access patterns (as simple as loop orders).  And we've discussed the potential speedup offered by parallelism with the caveat that systems and memory factors may impact _more_ than parallelism can help.\n",
    "\n",
    "Let's run some trials now to see these effects in reality!  We'll use $N \\times N$ matrices where $N=2000$.\n",
    "\n",
    "Read each cell, consider the accuracy of the timestamps, and then run (and wait...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RE3qxckYAr82"
   },
   "source": [
    "### Python (naÃ¯ve _v._ Numpy)\n",
    "This may run for a while..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LLTijA213ZA_"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "def matrix_multiply(A, B):\n",
    "    N = len(A)\n",
    "    C = [[0] * N for _ in range(N)]\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            for k in range(N):\n",
    "                C[i][j] += A[i][k] * B[k][j]\n",
    "    return C\n",
    "\n",
    "def benchmark_matmul(N, use_numpy=False):\n",
    "    # Initialize matrices with random values\n",
    "    if use_numpy:\n",
    "        A = np.random.randint(0, 10, (N, N))\n",
    "        B = np.random.randint(0, 10, (N, N))\n",
    "    else:\n",
    "        A = [[np.random.randint(0, 10) for _ in range(N)] for _ in range(N)]\n",
    "        B = [[np.random.randint(0, 10) for _ in range(N)] for _ in range(N)]\n",
    "\n",
    "    # Benchmark\n",
    "    start_time = time.time()\n",
    "\n",
    "    if use_numpy:\n",
    "        C = np.dot(A, B)\n",
    "    else:\n",
    "        C = matrix_multiply(A, B)\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    print(f\"Time taken for matrix multiplication of size {N}x{N}: {end_time - start_time:.6f} seconds (using {'NumPy' if use_numpy else 'custom function'})\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    N = 2000  # Example matrix size\n",
    "    print(\"\\nBenchmarking NumPy matrix multiplication:\")\n",
    "    benchmark_matmul(N, use_numpy=True)\n",
    "\n",
    "    print(\"\\nBenchmarking custom matrix multiplication:\")\n",
    "    # NOTE: only uncomment this for one test run (do not submit with this uncommented)\n",
    "    # benchmark_matmul(N)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0PVfNgLbCNw3"
   },
   "source": [
    "### C++\n",
    "You'll note that the naÃ¯ve C++ implementation may not necessarily beat Numpy, either!  Their optimizations (BLAS, etc.) really are excellent!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jtGmRLqvAxsV",
    "outputId": "27ec4a0c-4535-4128-e1dd-a150d494490e"
   },
   "outputs": [],
   "source": [
    "%%cpurun -n benchSimpleMatrixMul.cpp\n",
    "\n",
    "#include <iostream>\n",
    "#include <cstdlib>\n",
    "#include <ctime>\n",
    "#include <chrono>\n",
    "\n",
    "// Define matrix size N\n",
    "const int N = 2000;\n",
    "\n",
    "// Static global arrays\n",
    "int A[N][N];\n",
    "int B[N][N];\n",
    "int C[N][N];\n",
    "\n",
    "void matrix_multiply() {\n",
    "    for (int i = 0; i < N; ++i) {\n",
    "        for (int j = 0; j < N; ++j) {\n",
    "            C[i][j] = 0;\n",
    "            for (int k = 0; k < N; ++k) {\n",
    "                C[i][j] += A[i][k] * B[k][j];\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "void benchmark_matmul() {\n",
    "    // Initialize matrices with random values\n",
    "    srand(static_cast<unsigned>(time(0)));\n",
    "    for (int i = 0; i < N; ++i) {\n",
    "        for (int j = 0; j < N; ++j) {\n",
    "            A[i][j] = rand() % 10;\n",
    "            B[i][j] = rand() % 10;\n",
    "        }\n",
    "    }\n",
    "\n",
    "    // Benchmark\n",
    "    auto start = std::chrono::high_resolution_clock::now();\n",
    "    matrix_multiply();\n",
    "    auto end = std::chrono::high_resolution_clock::now();\n",
    "\n",
    "    std::chrono::duration<double> duration = end - start;\n",
    "    std::cout << \"Time taken for matrix multiplication of size \" << N << \"x\" << N << \": \"\n",
    "         << duration.count() << \" seconds\" << std::endl;\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    benchmark_matmul();\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZH0H4-F0Hz6d"
   },
   "source": [
    "### Compiler Optimizations\n",
    "\n",
    "This implementation outperforms both naÃ¯ve C++ and NumPy by leveraging advanced compiler optimizations such as `-Ofast`, `-funroll-loops`, and `-march=native`. These optimizations enhance performance by exploiting architecture-specific details!  Many people even [walk](https://arxiv.org/pdf/2105.07202) the large search space of optimization flags to find the best configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UcJrfrS7Bxfl",
    "outputId": "26338fb7-aac1-42fb-eceb-6a6768a3a6b6"
   },
   "outputs": [],
   "source": [
    "!cp benchSimpleMatrixMul.cpp benchmarkOptimizedMatrixMul.cpp\n",
    "!g++ -Ofast -funroll-loops -march=native benchmarkOptimizedMatrixMul.cpp -o benchmarkOptimizedMatrixMul\n",
    "!./benchmarkOptimizedMatrixMul"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bH5UvaBDPsNn"
   },
   "source": [
    "### Cache-Friendlier Implementations\n",
    "In class, we showed that `averageMatrix()` where loop order changed could be 5x faster.  Before you dig into the differences in the code below, could you think of optimizations for the multiplication given how memory is laid out for C++?  Also consider caching and ways to share temporally local data.\n",
    "\n",
    "![matrix mult example](https://raw.githubusercontent.com/COMS-BC3159-F24/image_assets/main/rowmajor.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "35rmdZS3OrE8",
    "outputId": "2b57f78b-e45c-4054-c2f3-6cc95341b106"
   },
   "outputs": [],
   "source": [
    "%%cpurun -n cacheFriendlyMatrixMul.cpp\n",
    "\n",
    "#include <iostream>\n",
    "#include <cstdlib>\n",
    "#include <ctime>\n",
    "#include <chrono>\n",
    "\n",
    "// Define matrix size N\n",
    "const int N = 2000;\n",
    "\n",
    "// Static global arrays\n",
    "int A[N][N];\n",
    "int B[N][N];\n",
    "int C[N][N];\n",
    "\n",
    "void matrix_multiply() {\n",
    "    for (int i = 0; i < N; ++i) {\n",
    "        for (int k = 0; k < N; ++k) {\n",
    "            for (int j = 0; j < N; ++j) {\n",
    "                C[i][j] += A[i][k] * B[k][j];\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "void benchmark_matmul() {\n",
    "    // Initialize matrices with random values\n",
    "    srand(static_cast<unsigned>(time(0)));\n",
    "    for (int i = 0; i < N; ++i) {\n",
    "        for (int j = 0; j < N; ++j) {\n",
    "            A[i][j] = rand() % 10;\n",
    "            B[i][j] = rand() % 10;\n",
    "            C[i][j] = 0;\n",
    "        }\n",
    "    }\n",
    "\n",
    "    // Benchmark\n",
    "    auto start = std::chrono::high_resolution_clock::now();\n",
    "    matrix_multiply();\n",
    "    auto end = std::chrono::high_resolution_clock::now();\n",
    "\n",
    "    std::chrono::duration<double> duration = end - start;\n",
    "    std::cout << \"Time taken for matrix multiplication of size \" << N << \"x\" << N << \": \"\n",
    "         << duration.count() << \" seconds\" << std::endl;\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    benchmark_matmul();\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Eiq4wZnCQ0iO"
   },
   "source": [
    "Adding optimization flags, now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pJThKeJ8Qug5",
    "outputId": "6fdf44a8-3c81-4aef-815e-373233d756a8"
   },
   "outputs": [],
   "source": [
    "!cp cacheFriendlyMatrixMul.cpp cacheFriendlyMatrixMulOpt.cpp\n",
    "!g++ -Ofast -funroll-loops -march=native cacheFriendlyMatrixMulOpt.cpp -o cacheFriendlyMatrixMulOpt\n",
    "!./cacheFriendlyMatrixMulOpt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "To0kisE8RFqs"
   },
   "source": [
    "**WOW!**  Now we're really flying?!  If you have extra time, take this a step further!  \n",
    "1. Can you write a program that's even more cache aware?\n",
    "2. What about benchmarking your CUDA implementation?  Is it better/worse?  Why so?"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "q1-python-matmul": {
     "name": "q1-python-matmul",
     "points": 3,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2-cpp-matmul": {
     "name": "q2-cpp-matmul",
     "points": 4,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3-cpp-float-matmul": {
     "name": "q3-cpp-float-matmul",
     "points": 1,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4-cuda-float-matmul": {
     "name": "q4-cuda-float-matmul",
     "points": 5,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q5-cuda-large": {
     "name": "q5-cuda-large",
     "points": 2,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
