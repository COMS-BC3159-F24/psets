{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xTKiGPkJ5qRy"
   },
   "source": [
    "# PSET 3: Exploring Taylor Expansions and DDP\n",
    "\n",
    "...\n",
    "\n",
    "Try not to add additional cells nor rearrange any that exist now as it will mess with our autograder (but feel free to open another Colab/notebook on the side).\n",
    "\n",
    "### Make sure to submit your final notebook with all of your solutions to Gradescope!\n",
    "[Direct Gradescope Link](https://www.gradescope.com/courses/820552)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TOusEnXk5qRz"
   },
   "source": [
    "### Before Starting\n",
    "\n",
    "This problem set is written in only Python, but we do have a few \"hacks\" in place to display graphics in the cell outputs of this interactive notebook.  We'll also need a few libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_t8fU8-85qR0",
    "outputId": "0179e509-7fc2-4896-fbdd-21ea0265cf78"
   },
   "outputs": [],
   "source": [
    "!pip3 install \"pygame>2.1\" \"numpy>1.23\" \"scipy>1.9\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "3KsZoHydPptM"
   },
   "source": [
    "## Part 1: Taylor Approximations of Dynamics and Cost Functions (7 Points)\n",
    "\n",
    "In this problem set, we'll first implement a few dynamics and cost helper functions that we'll use in the larger trajopt functions.  Functions to update:\n",
    "* `next_state`\n",
    "* `next_state_gradient`\n",
    "* `cost_value`\n",
    "* `cost_gradient`\n",
    "* `cost_hessian`\n",
    "\n",
    "**Note:** most things are of type [`np.array`](https://numpy.org/doc/stable/user/quickstart.html) which hopefully should simplify your linear algebra and there are a few more hints left in the code comments! Also, make sure to take into account both the states and the controls!\n",
    "\n",
    "---\n",
    "\n",
    "### Step 1: `next_state`\n",
    "We'll begin by converting the pendulum physics functions which compute acceleration (`dynamics`) into `next_state`.  We assume a pendulum with the following variables:\n",
    "\n",
    "- $q$: Position (angle) of the pendulum.\n",
    "- $\\dot{q}$ (or `qd`): Velocity (angular velocity) of the pendulum.\n",
    "- $\\ddot{q}$ (or `qdd`): Acceleration (angular acceleration) of the pendulum.\n",
    "\n",
    "The pendulum dynamics—i.e., acceleration—are influenced by:\n",
    "- Gravity ($g$), which depends on the pendulum's position.\n",
    "- $\\text{damping}$, coefficient which depends on the pendulum's velocity.\n",
    "- A control input $u$, which directly affects the acceleration.\n",
    "\n",
    "$$\n",
    "\\ddot{q} = u - g \\cdot \\sin(q) - \\text{damping} \\cdot \\dot{q}\n",
    "$$\n",
    "\n",
    "The dynamics are computed for you as follows:\n",
    "\n",
    "```python\n",
    "def dynamics(self, x, u):\n",
    "   position = x[0]\n",
    "   velocity = x[1]\n",
    "   qdd = u - self.gravity*sin(position) - self.damping*velocity\n",
    "   return np.array(qdd)\n",
    "```\n",
    "\n",
    "Recall from class that Euler integration is used to approximate the next state of the system by stepping forward in time with a small time step $dt$ (`self.timestep`). The update equations for the state variables $q$ (position) and $\\dot{q}$ (velocity) are calculated by adding a small amount of acceleration and velocity to the original position and velocity.\n",
    "\n",
    "$$\n",
    "q' = q + dt \\cdot \\dot{q}\n",
    "$$\n",
    "$$\n",
    "\\dot{q}' = \\dot{q} + dt \\cdot \\ddot{q}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $q'$ (or `q'`) is the next position.\n",
    "- $\\dot{q}'$ (or `qd'` in the code) is the next velocity.\n",
    "- $\\ddot{q}$ (or `qdd`) is the acceleration, computed via the provided `dynamics()` function.\n",
    "\n",
    "So, for `next_state`, you should return a vector\n",
    "```text\n",
    "[q', qd'] = [q, qd] + dt * [qd, qdd]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Step 2: `next_state_gradient`\n",
    "\n",
    "The dynamics of the system depend on both the current state $[q, \\dot{q}]$ and the control input $u$. We define two gradient matrices:\n",
    "\n",
    "```text\n",
    "             A = [[dq'/dq, dq'/dqd],    and B = [[dq/du],\n",
    "                  [dqd'/dq, dqd'/dqd]]           [dqd/du]]\n",
    "```\n",
    "\n",
    "- $\\mathbf{A}$: The gradient of the next state with respect to the current state $[q, \\dot{q}]$.\n",
    "- $\\mathbf{B}$: The gradient of the next state with respect to the control input $u$.\n",
    "\n",
    "In mathematical notation (if it helps):\n",
    "$$\n",
    "A = \\begin{bmatrix} \n",
    "        \\frac{\\partial q'}{\\partial q} & \\frac{\\partial q'}{\\partial \\dot{q}} \\\\[10pt]\n",
    "        \\frac{\\partial \\dot{q}'}{\\partial q} & \\frac{\\partial \\dot{q}'}{\\partial \\dot{q}} \n",
    "    \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "B = \\begin{bmatrix} \n",
    "        \\frac{\\partial q}{\\partial u} \\\\[10pt]\n",
    "        \\frac{\\partial \\dot{q}}{\\partial u} \n",
    "    \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "Your task is to construct these matrices which includes taking partial derivatives of $q'$ (`q'`) and $\\dot{q}'$ (`qd'`) which you computed in Step 1 (but their equations were provided above, anyway) and also applying the chain rule.  (Yes, this was done in examples in lecture slides where $h$ represents the timestep `dt` or `self.timestep`.  But try to do this yourself with the notation provided in this problem set!)\n",
    "\n",
    "We (hopefully) have made your life easier by providing the partial derivatives of $\\ddot{q}$ (i.e., acceleration or `qdd`) to show how small changes in the current state and control input affect the acceleration:\n",
    "\n",
    "1. Derivative of acceleration with respect to position: $\\frac{\\partial \\ddot{q}}{\\partial q} = -g \\cdot \\cos(q)$\n",
    "2. Derivative of acceleration with respect to velocity: $\\frac{\\partial \\ddot{q}}{\\partial \\dot{q}} = -\\text{damping}$\n",
    "\n",
    "3. Derivative of acceleration with respect to the control input: $\\frac{\\partial \\ddot{q}}{\\partial u} = 1$\n",
    "\n",
    "```python\n",
    "def dynamics_gradient(self, x, u):\n",
    "    position = x[0]  # q\n",
    "    velocity = x[1]  # qd\n",
    "    # acceleration (or qdd) = u - self.gravity*sin(position) - self.damping*velocity\n",
    "\n",
    "    dqdd_dq = -self.gravity * np.cos(position)\n",
    "    dqdd_dqd = -self.damping\n",
    "    dqdd_du = 1\n",
    "    return np.array([dqdd_dq, dqdd_dqd, dqdd_du])\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Step 3: Cost Helper Functions\n",
    "\n",
    "Next, we'll move onto the cost functions. Here we need to implement the cost value, gradient, and Hessian. For this problem, we are going to use the \"standard simple quadratic cost\":\n",
    "\n",
    "$$\n",
    "\\text{cost}(x,u) = 0.5(x-x_g)^T Q (x-x_g) + 0.5 u^T R u\n",
    "$$\n",
    "\n",
    "- $x$: State variable vector (i.e., $\\begin{bmatrix} q, \\dot{q}\\end{bmatrix}$).\n",
    "- $u$: Control input\n",
    "- $x_g$: Goal state.\n",
    "- $\\mathbf{Q}$: A matrix that weighs the state cost.\n",
    "- $\\mathbf{R}$: A matrix that weighs the control cost.\n",
    "\n",
    "As that outputs a scalar value, the cost gradient and Hessian, therefore, are of the form:\n",
    "\n",
    "```text\n",
    "g = [dcost/dq, dcost/dqd, dcost/du]\n",
    "H = [[d^2cost/dq^2,   d^2cost/dq dqd, d^2cost/dq du],\n",
    "     [d^2cost/dqd dq, dcost/dqd^2,    d^2cost/dqd du],\n",
    "     [d^2cost/du dq,  dcost/du dqd,   d^2cost/du^2]]\n",
    "```\n",
    "\n",
    "In mathematical notation:\n",
    "$$\\mathbf{g} = \\begin{bmatrix}\\frac{\\partial \\text{cost}}{\\partial x}, \\frac{\\partial \\text{cost}}{\\partial u}\\end{bmatrix}$$\n",
    "\n",
    "$$\\mathbf{H} = \\begin{bmatrix}\n",
    "\\frac{\\partial^2 \\text{cost}}{\\partial q^2} & \\frac{\\partial^2 \\text{cost}}{\\partial q \\, \\partial \\dot{q}} & \\frac{\\partial^2 \\text{cost}}{\\partial q \\, \\partial u} \\\\[10pt]\n",
    "\\frac{\\partial^2 \\text{cost}}{\\partial \\dot{q} \\, \\partial q} & \\frac{\\partial^2 \\text{cost}}{\\partial \\dot{q}^2} & \\frac{\\partial^2 \\text{cost}}{\\partial \\dot{q} \\, \\partial u} \\\\[10pt]\n",
    "\\frac{\\partial^2 \\text{cost}}{\\partial u \\, \\partial q} & \\frac{\\partial^2 \\text{cost}}{\\partial u \\, \\partial \\dot{q}} & \\frac{\\partial^2 \\text{cost}}{\\partial u^2}\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "\n",
    "\n",
    "In this step, please implement the following functions:\n",
    "\n",
    "1. `cost_value(x, u)` - computes the cost value based on the formula provided.\n",
    "2. `cost_gradient(x, u)` - computes the gradient of the cost value with respect to the states and control inputs.\n",
    "3. `cost_hessian(x, u)` - computes the Hessian of the cost value.\n",
    "\n",
    "$Q$ and $R$ are provided (find them in `self.Q` and `self.R`), as is the goal $x_g$ (in `self.goal`). And you may find our `block_diag()` helper useful in this step (e.g., when constructing the Hessian)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from math import sin, cos, pi\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "class Pendulum():\n",
    "    def __init__(self, timestep = 0.15, gravity = 9.81, damping = 0.01, control_min = -5, control_max = 5, control_step = 0.25):\n",
    "        self.timestep = timestep\n",
    "        self.gravity = gravity\n",
    "        self.damping = damping\n",
    "        self.control_min = control_min\n",
    "        self.control_max = control_max\n",
    "        self.control_step = control_step\n",
    "        self.Q = None\n",
    "        self.R = None\n",
    "        self.QF = None\n",
    "        self.goal = None\n",
    "\n",
    "    ######################\n",
    "    #                    #\n",
    "    # High level helpers #\n",
    "    #                    #\n",
    "    ######################\n",
    "\n",
    "    # return the state and control size\n",
    "    def get_state_size(self):\n",
    "        return 2\n",
    "    def get_control_size(self):\n",
    "        return 1\n",
    "\n",
    "    # clamp the input n to the range [smallest, largest]\n",
    "    def clamp(self, n, smallest, largest):\n",
    "        return max(smallest, min(n, largest))\n",
    "\n",
    "    # ensure angles are between -pi and pi\n",
    "    def wrap_angles(self, angle):\n",
    "        upper_bound = pi\n",
    "        lower_bound = -pi\n",
    "        while (angle < lower_bound):\n",
    "            angle += 2*pi\n",
    "        while (angle > upper_bound):\n",
    "            angle -= 2*pi\n",
    "        return np.array(angle)\n",
    "\n",
    "    # compute the difference between two states making sure to wrap angles\n",
    "    def state_delta(self, state1, state2):\n",
    "        return np.array([self.wrap_angles(state1[0]-state2[0]), state1[1]-state2[1]])\n",
    "\n",
    "    #####################################################\n",
    "    #                                                   #\n",
    "    #  Helper functions you need to fill out start here #\n",
    "    #                                                   #\n",
    "    #####################################################\n",
    "\n",
    "    ######################\n",
    "    #                    #\n",
    "    #  Physics helpers   #\n",
    "    #                    #\n",
    "    ######################\n",
    "\n",
    "    # apply the physics of the pendulum to compute acceleration\n",
    "    def dynamics(self, x, u):\n",
    "        position = x[0]\n",
    "        velocity = x[1]\n",
    "        # acceleration (or qdd) = u - self.gravity*sin(position) - self.damping*velocity\n",
    "        qdd = u - self.gravity*sin(position) - self.damping*velocity\n",
    "        return np.array(qdd)\n",
    "\n",
    "    # compute the gradient of applying physics of the pendulum to compute acceleration\n",
    "    def dynamics_gradient(self, x, u):\n",
    "        position = x[0]\n",
    "        velocity = x[1]\n",
    "\n",
    "        # acceleration (or qdd) = u - self.gravity*sin(position) - self.damping*velocity\n",
    "        dqdd_dq = -self.gravity*cos(position)   # derivative of qdd w.r.t. q\n",
    "        dqdd_dqd = -self.damping                # derivative of qdd w.r.t. qd\n",
    "        dqdd_du = 1                             # derivative of qdd w.r.t. u\n",
    "        return np.array([dqdd_dq, dqdd_dqd, dqdd_du])\n",
    "\n",
    "    # compute the next state using euler integration\n",
    "    def next_state(self, x, u):\n",
    "        position = np.array(x[0])\n",
    "        velocity = np.array(x[1])\n",
    "\n",
    "        # first compute acceleration using dynamics\n",
    "        # note: in this case we also clamp the input to control_min/max\n",
    "        #       to avoid unrealistic steps (this can be safely ignored in the gradient)\n",
    "        u_clamp = self.clamp(u, self.control_min, self.control_max)\n",
    "        acceleration = self.dynamics(x,u_clamp)\n",
    "\n",
    "        #\n",
    "        # TODO\n",
    "        #\n",
    "        # Euler integrator [q', qd'] = [q, qd] + dt * [qd, qdd]\n",
    "        # note: * make sure to wrap_angles where appropriate\n",
    "        #       * position and velocity are already numpy arrays\n",
    "        #         so keep that in mind when constructing the next state\n",
    "        #         return value\n",
    "        #\n",
    "        ...\n",
    "\n",
    "        return np.array([0,0])\n",
    "\n",
    "\n",
    "    # compute the gradient of the next state function using euler integration\n",
    "    def next_state_gradient(self, x, u):\n",
    "        position = x[0]\n",
    "        velocity = x[1]\n",
    "        A = np.array([[0, 0], [0, 0]])\n",
    "        B = np.array([[0], [0]])\n",
    "\n",
    "        #\n",
    "        # TODO\n",
    "        #\n",
    "        # Euler integrator [q', qd'] = [q, qd] + dt * [qd, qdd]\n",
    "        # Return the partial derivative matricies:\n",
    "        #     A = [[dq'/dq, dq'/dqd],    and B = [[dq/du],\n",
    "        #          [dqd'/dq, dqd'/dqd]]           [dqd/du]]\n",
    "        #\n",
    "        #\n",
    "        ...\n",
    "        return A, B\n",
    "\n",
    "\n",
    "\n",
    "    ######################\n",
    "    #                    #\n",
    "    #    Cost helpers    #\n",
    "    #                    #\n",
    "    ######################\n",
    "\n",
    "    def set_Q(self, Q):\n",
    "        self.Q = Q\n",
    "    def set_R(self, R):\n",
    "        self.R = R\n",
    "    def set_QF(self, QF):\n",
    "        self.QF = QF\n",
    "    def set_goal(self, goal):\n",
    "        self.goal = goal\n",
    "\n",
    "    # compute the cost of the form 0.5(x-xg)^TQ(x-xg) + 0.5u^TRu\n",
    "    # note that if u=None then it is the final state and there is no control (use QF)\n",
    "    def cost_value(self, x, u = None):\n",
    "        cost = 0\n",
    "        # first compute the error between the current state and the goal\n",
    "        delta = self.state_delta(x, self.goal)\n",
    "        # then compute the cost for that error\n",
    "        #\n",
    "        # TODO\n",
    "        #\n",
    "        # hint: np.matmul may be useful!\n",
    "        ...\n",
    "        return 0\n",
    "\n",
    "    # compute the gradient of the cost of the form 0.5(x-xg)^TQ(x-xg) + 0.5u^TRu\n",
    "    # note that if u=None then it is the final state and there is no control (use QF)\n",
    "    #\n",
    "    # return the vector [dcost/dq, dcost/dqd, dcost/du]\n",
    "    def cost_gradient(self, x, u = None):\n",
    "        grad = []\n",
    "        # first compute the error between the current state and the goal\n",
    "        delta = self.state_delta(x, self.goal)\n",
    "        # then compute the cost gradient with respect to the state\n",
    "        #\n",
    "        # TODO\n",
    "        #\n",
    "        if u is not None:\n",
    "            # hint: np.matmul and np.hstack may be useful!\n",
    "            ...\n",
    "            return np.array([0,0,0])\n",
    "        else:\n",
    "            ...\n",
    "            return np.array([0,0])\n",
    "\n",
    "    # compute the hessian of the cost of the form 0.5(x-xg)^TQ(x-xg) + 0.5u^TRu\n",
    "    # note that if u=None then it is the final state and there is no control (use QF)\n",
    "    #\n",
    "    # return the matrix [[d^2cost/dq^2,   d^2cost/dq dqd, d^2cost/dq du],\n",
    "    #                    [d^2cost/dqd dq, dcost/dqd^2,    d^2cost/dqd du],\n",
    "    #                    [d^2cost/du dq,  dcost/du dqd,   d^2cost/du^2]]\n",
    "    #\n",
    "    # Hint: you may find the block_diag helper function helpful! (But you don't need to use it)\n",
    "    #\n",
    "    def cost_hessian(self, x, u = None):\n",
    "        H = [[]]\n",
    "        #\n",
    "        # TODO\n",
    "        #\n",
    "        # hint: if u is None then you only need the hessian with respect to q, qd\n",
    "        #\n",
    "        if u is not None:\n",
    "            ...\n",
    "            return np.zeros((3,3))\n",
    "        else:\n",
    "            ...\n",
    "            return np.zeros((2,2))\n",
    "\n",
    "    def cost_gradient_hessian(self, x, u = None):\n",
    "        return self.cost_hessian(x,u), self.cost_gradient(x,u)\n",
    "\n",
    "    def block_diag(self, *arrs):\n",
    "        \"\"\"Create a block diagonal matrix from the provided arrays.\n",
    "\n",
    "        Given the inputs `A`, `B` and `C`, the output will have these\n",
    "        arrays arranged on the diagonal::\n",
    "\n",
    "            [[A, 0, 0],\n",
    "             [0, B, 0],\n",
    "             [0, 0, C]]\n",
    "\n",
    "        If all the input arrays are square, the output is known as a\n",
    "        block diagonal matrix.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        A, B, C, ... : array-like, up to 2D\n",
    "            Input arrays.  A 1D array or array-like sequence with length n is\n",
    "            treated as a 2D array with shape (1,n).\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        D : ndarray\n",
    "            Array with `A`, `B`, `C`, ... on the diagonal.  `D` has the\n",
    "            same dtype as `A`.\n",
    "\n",
    "        References\n",
    "        ----------\n",
    "        .. [1] Wikipedia, \"Block matrix\",\n",
    "               http://en.wikipedia.org/wiki/Block_diagonal_matrix\n",
    "\n",
    "        Examples\n",
    "        --------\n",
    "        >>> A = [[1, 0],\n",
    "        ...      [0, 1]]\n",
    "        >>> B = [[3, 4, 5],\n",
    "        ...      [6, 7, 8]]\n",
    "        >>> C = [[7]]\n",
    "        >>> print(block_diag(A, B, C))\n",
    "        [[1 0 0 0 0 0]\n",
    "         [0 1 0 0 0 0]\n",
    "         [0 0 3 4 5 0]\n",
    "         [0 0 6 7 8 0]\n",
    "         [0 0 0 0 0 7]]\n",
    "        >>> block_diag(1.0, [2, 3], [[4, 5], [6, 7]])\n",
    "        array([[ 1.,  0.,  0.,  0.,  0.],\n",
    "               [ 0.,  2.,  3.,  0.,  0.],\n",
    "               [ 0.,  0.,  0.,  4.,  5.],\n",
    "               [ 0.,  0.,  0.,  6.,  7.]])\n",
    "\n",
    "        \"\"\"\n",
    "        if arrs == ():\n",
    "            arrs = ([],)\n",
    "        arrs = [np.atleast_2d(a) for a in arrs]\n",
    "\n",
    "        bad_args = [k for k in range(len(arrs)) if arrs[k].ndim > 2]\n",
    "        if bad_args:\n",
    "            raise ValueError(\"arguments in the following positions have dimension \"\n",
    "                                \"greater than 2: %s\" % bad_args)\n",
    "\n",
    "        shapes = np.array([a.shape for a in arrs])\n",
    "        out = np.zeros(np.sum(shapes, axis=0), dtype=arrs[0].dtype)\n",
    "\n",
    "        r, c = 0, 0\n",
    "        for i, (rr, cc) in enumerate(shapes):\n",
    "            out[r:r + rr, c:c + cc] = arrs[i]\n",
    "            r += rr\n",
    "            c += cc\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Part 2 - Explore\n",
    "Now that you have a working helper functions we'll use the DDP implementation below to allow us to solve some trajectory optimization problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# This program runs the main algorithms built on top of your util functions\n",
    "# (Do not modify, but please read)\n",
    "\n",
    "import math, pygame, copy, time\n",
    "import IPython.display as ipydisplay\n",
    "from pygame.locals import *\n",
    "from time import sleep\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "class Trajopt:\n",
    "    def __init__(self, robot_object, start_node, goal_node, N, XMAX_MIN, YMAX_MIN, \\\n",
    "                       MAX_ITER = 100, EXIT_TOL = 1e-3, ALPHA_FACTOR = 0.5, ALPHA_MIN = 1e-4, MU = 5):\n",
    "        self.robot_object = robot_object # the robot_object with physics and cost functions\n",
    "        self.MAX_ITER = MAX_ITER         # total ddp loops to try\n",
    "        self.EXIT_TOL = EXIT_TOL         # This is the convergence criterion. We will declare success when the trajectory\n",
    "                                         # is updated by a norm of less that 1e-4. DO NOT MODIFY.\n",
    "        self.N = N                       # Number of nodes in a trajectory\n",
    "        self.start_node = start_node\n",
    "        self.goal_node = goal_node\n",
    "        self.XMAX_MIN = XMAX_MIN         # max for drawing locically\n",
    "        self.YMAX_MIN = YMAX_MIN         # max for drawing locically\n",
    "        self.canvas_max = 640            # max for drawing pixels\n",
    "        # set global line search parameters\n",
    "        self.alpha_factor = ALPHA_FACTOR # how much to reduce alpha by each deeper search\n",
    "        self.alpha_min = ALPHA_MIN       # minimum alpha to try\n",
    "        self.mu = MU                     # merit function weighting\n",
    "\n",
    "    def draw_circle(self, node, size, color):\n",
    "        percent_x = (node[0] + self.XMAX_MIN) / 2 / self.XMAX_MIN\n",
    "        percent_y = (node[1] + self.YMAX_MIN) / 2 / self.YMAX_MIN\n",
    "\n",
    "        scaled_x = int(self.canvas_max*percent_x)\n",
    "        scaled_y = int(self.canvas_max*percent_y)\n",
    "\n",
    "        pygame.draw.circle(self.screen, color, (scaled_x, scaled_y), size)\n",
    "\n",
    "    def draw_line(self, node1, node2, color):\n",
    "        percent_x1 = (node1[0] + self.XMAX_MIN) / 2 / self.XMAX_MIN\n",
    "        percent_y1 = (node1[1] + self.YMAX_MIN) / 2 / self.YMAX_MIN\n",
    "        percent_x2 = (node2[0] + self.XMAX_MIN) / 2 / self.XMAX_MIN\n",
    "        percent_y2 = (node2[1] + self.YMAX_MIN) / 2 / self.YMAX_MIN\n",
    "\n",
    "        scaled_x1 = int(self.canvas_max*percent_x1)\n",
    "        scaled_y1 = int(self.canvas_max*percent_y1)\n",
    "        scaled_x2 = int(self.canvas_max*percent_x2)\n",
    "        scaled_y2 = int(self.canvas_max*percent_y2)\n",
    "\n",
    "        # check if angle wrapping (and don't draw lines across the screen)\n",
    "        if node1[0] - node2[0] > math.pi:\n",
    "            pass\n",
    "        elif node1[0] - node2[0] < -math.pi:\n",
    "            pass\n",
    "        else:\n",
    "            pygame.draw.line(self.screen, color, (scaled_x2, scaled_y2), (scaled_x1, scaled_y1))\n",
    "\n",
    "    def init_screen(self):\n",
    "        # initialize and prepare screen\n",
    "        pygame.init()\n",
    "        self.screen = pygame.display.set_mode((self.canvas_max,self.canvas_max))\n",
    "        pygame.display.set_caption('PS3 - DDP')\n",
    "        black = 20, 20, 40\n",
    "        blue = 0, 0, 255\n",
    "        green = 0, 255, 0\n",
    "        self.screen.fill(black)\n",
    "        self.draw_circle(self.start_node, 5, blue)\n",
    "        self.draw_circle(self.goal_node, 5, green)\n",
    "        pygame.display.update()\n",
    "\n",
    "    def draw_trajectory(self, x):\n",
    "        white = 255, 240, 200\n",
    "        red = 255, 0, 0\n",
    "\n",
    "        # Draw the trajectory\n",
    "        self.draw_circle(x[:,0], 2, white)\n",
    "        for k in range(1, self.N):\n",
    "            self.draw_circle(x[:,k], 2, white)\n",
    "            self.draw_line(x[:,k-1], x[:,k], red)\n",
    "\n",
    "        pygame.display.update()\n",
    "\n",
    "        # Capture the screen and display in Colab\n",
    "        pygame.image.save(self.screen, \"/tmp/screenshot.png\")\n",
    "        ipydisplay.display(ipydisplay.Image(\"/tmp/screenshot.png\"))\n",
    "\n",
    "        time.sleep(0.4)\n",
    "\n",
    "    def solve(self, x, u, N, DISPLAY_MODE = False):\n",
    "        # start up the graphics\n",
    "        self.init_screen()\n",
    "\n",
    "        # get constants\n",
    "        nx = self.robot_object.get_state_size()\n",
    "        nu = self.robot_object.get_control_size()\n",
    "\n",
    "        # solve\n",
    "        self.iLQR(x, u, nx, nu, N, DISPLAY_MODE)\n",
    "\n",
    "\n",
    "    #####################################################\n",
    "    #                                                   #\n",
    "    #                    iLQR Helpers                   #\n",
    "    #                                                   #\n",
    "    #####################################################\n",
    "\n",
    "    # Compute the total cost along the trajectory\n",
    "    def compute_total_cost(self, x, u, nx, nu, N):\n",
    "        J = 0\n",
    "        for k in range(N-1):\n",
    "            J += self.robot_object.cost_value(x[:,k], u[:,k])\n",
    "        J += self.robot_object.cost_value(x[:,N-1])\n",
    "        return J\n",
    "\n",
    "    # compute the dynamics and cost gradient and hessians\n",
    "    def compute_approximation(self, xk, uk, nx, nu, k):\n",
    "        Gk, gk = self.robot_object.cost_gradient_hessian(xk, uk)\n",
    "        Ak, Bk = self.robot_object.next_state_gradient(xk, uk)\n",
    "        return Ak, Bk, Gk, gk\n",
    "\n",
    "    # put most of the above backward pass functions together and get from\n",
    "    # the inputs to return the current kappa, K, Vxx, Vx\n",
    "    def backward_pass_iterate(self, A, B, H, g, Vxx_kp1, Vx_kp1, nx, nu, k):\n",
    "        # Backpropogate the CTG through the dynamics\n",
    "        Hxx = np.matmul(A.transpose(),np.matmul(Vxx_kp1,A)) + H[0:nx,0:nx]\n",
    "        Huu = np.matmul(B.transpose(),np.matmul(Vxx_kp1,B)) + H[nx:,nx:]\n",
    "        Hux = np.matmul(B.transpose(),np.matmul(Vxx_kp1,A)) + H[nx:,0:nx]\n",
    "        gx = np.matmul(A.transpose(),Vx_kp1) + g[0:nx]\n",
    "        gu = np.matmul(B.transpose(),Vx_kp1) + g[nx:]\n",
    "\n",
    "        # Invert Huu block\n",
    "        HuuInv = np.linalg.inv(Huu)\n",
    "\n",
    "        # Compute feedback and feedforward updates\n",
    "        K = -np.matmul(HuuInv,Hux)\n",
    "        kappa = -np.matmul(HuuInv,gu)\n",
    "\n",
    "        # Compute the next CTG estimate\n",
    "        Vxx = Hxx - np.matmul(Hux.transpose(),K)\n",
    "        Vx = gx - np.matmul(Hux.transpose(),kappa)\n",
    "\n",
    "        return kappa, K, Vxx, Vx\n",
    "\n",
    "    # return u_new based on the current x_new, k, kappa, alpha, and original x\n",
    "    def compute_control_update(self, x, x_new, K, kappa, alpha, nx, nu, N):\n",
    "        delta = self.robot_object.state_delta(x_new, x)\n",
    "        return alpha*kappa + np.matmul(K,delta)\n",
    "\n",
    "    # rollout the full trajectory to produce x_new, u_new based on\n",
    "    # x, u (the original trajectory), as well as K, kappa, alpha (the updates)\n",
    "    def rollout_trajectory(self, x, u, K, kappa, alpha, nx, nu, N):\n",
    "        x_new = copy.deepcopy(x)\n",
    "        u_new = copy.deepcopy(u)\n",
    "        for k in range(N-1):\n",
    "            u_new[:,k] = u[:,k] + self.compute_control_update(x[:,k], x_new[:,k], K[:,:,k], kappa[:,k], alpha, nx, nu, k)\n",
    "            x_new[:,k+1] = self.robot_object.next_state(x_new[:,k], u_new[:,k])\n",
    "        return x_new, u_new\n",
    "\n",
    "    # main iLQR function\n",
    "    def iLQR(self, x, u, nx, nu, N, DISPLAY_MODE = False):\n",
    "\n",
    "        # allocate memory for things we will compute\n",
    "        kappa = np.zeros([nu,N-1])     # control updates\n",
    "        K = np.zeros((nu,nx,N-1))   # feedback gains\n",
    "\n",
    "        # compute initial cost\n",
    "        J = self.compute_total_cost(x, u, nx, nu, N)\n",
    "        J_prev = J\n",
    "        if DISPLAY_MODE:\n",
    "            print(\"Initial Cost: \", J)\n",
    "\n",
    "        # start the main loop\n",
    "        iteration = 0\n",
    "        failed = False\n",
    "        while 1:\n",
    "\n",
    "            # Do backwards pass to compute new control update and feedback gains: kappa and K\n",
    "            # start by initializing the cost to go\n",
    "            Vxx, Vx = self.robot_object.cost_gradient_hessian(x[:,N-1])\n",
    "            for k in range(N-2,-1,-1):\n",
    "                # then compute the quadratic approximation at that point\n",
    "                A, B, H, g = self.compute_approximation(x[:,k], u[:,k], nx, nu, k)\n",
    "\n",
    "                # then compute the control update and new CTG estimates\n",
    "                kappak, Kk, Vxx, Vx = self.backward_pass_iterate(A, B, H, g, Vxx, Vx, nx, nu, k)\n",
    "\n",
    "                # save kappa and K for forward pass\n",
    "                kappa[:,k] = kappak.tolist()\n",
    "                K[:,:,k] = Kk.tolist()\n",
    "\n",
    "            # Do forwards pass to compute new x, u, J (with line search)\n",
    "            alpha = 1\n",
    "            while 1:\n",
    "                # rollout new trajectory\n",
    "                x_new, u_new = self.rollout_trajectory(x, u, K, kappa, alpha, nx, nu, N)\n",
    "\n",
    "                # compute new cost\n",
    "                J_new = self.compute_total_cost(x_new, u_new, nx, nu, N)\n",
    "\n",
    "                # simple line search criteria\n",
    "                if J_new < J:\n",
    "                    J_prev = J\n",
    "                    x = x_new\n",
    "                    u = u_new\n",
    "                    J = J_new\n",
    "                    if DISPLAY_MODE:\n",
    "                        print(\"Iteration[\", iteration, \"] with cost[\", round(J,4), \"] and x final:\")\n",
    "                        print(x[:,N-1])\n",
    "                        self.draw_trajectory(x)\n",
    "                    break\n",
    "\n",
    "                # failed try to continue the line search\n",
    "                elif alpha > self.alpha_min:\n",
    "                    alpha *= self.alpha_factor\n",
    "                    if DISPLAY_MODE:\n",
    "                        print(\"Deepening the line search\")\n",
    "\n",
    "                # failed line search\n",
    "                else:\n",
    "                    if DISPLAY_MODE:\n",
    "                        print(\"Line search failed\")\n",
    "                    failed = True\n",
    "                    break\n",
    "\n",
    "            # Check for exit (or error)\n",
    "            if failed: # need double break to get out of both loops here if line search fails\n",
    "                break\n",
    "\n",
    "            delta_J = J_prev - J\n",
    "            if delta_J < self.EXIT_TOL:\n",
    "                if DISPLAY_MODE:\n",
    "                    print(\"Exiting for exit_tolerance\")\n",
    "                break\n",
    "\n",
    "            if iteration == self.MAX_ITER - 1:\n",
    "                if DISPLAY_MODE:\n",
    "                    print(\"Exiting for max_iter\")\n",
    "                break\n",
    "            else:\n",
    "                iteration += 1\n",
    "\n",
    "        if DISPLAY_MODE:\n",
    "            print(\"Final Trajectory\")\n",
    "            print(x)\n",
    "            print(u)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Let's change a few environment variables to [trick](https://colab.research.google.com/drive/1xtiBrGeRHmXY3KSOixkZBf_rJIgBImJu?usp=sharing#scrollTo=7X42jJWlAuSl) Google Colab into running pygame without error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# set SDL to use the dummy NULL video driver,\n",
    "#   so it doesn't need a windowing system.\n",
    "os.environ[\"SDL_VIDEODRIVER\"] = \"dummy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "from math import pi\n",
    "import numpy as np\n",
    "\n",
    "XMAX_MIN = pi\n",
    "YMAX_MIN = 10\n",
    "\n",
    "X_START = [0,0]\n",
    "X_GOAL = [pi,0]\n",
    "\n",
    "# How did I get these numbers? A little intuition and a lot of guess and check.\n",
    "QF = np.array([[30,0],[0,10]])\n",
    "Q = np.array([[3,0],[0,1]])\n",
    "R = np.array([0.08])\n",
    "\n",
    "N = 32\n",
    "\n",
    "pend = Pendulum()\n",
    "pend.set_Q(Q)\n",
    "pend.set_R(R)\n",
    "pend.set_QF(QF)\n",
    "pend.set_goal(X_GOAL)\n",
    "\n",
    "x0 = np.zeros([pend.get_state_size(),N])\n",
    "u0 = np.zeros([pend.get_control_size(),N-1])\n",
    "\n",
    "trajopt_obj = Trajopt(pend, X_START, X_GOAL, N, XMAX_MIN, YMAX_MIN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Run the solver!\n",
    "Run the solver. What happens? How does this work as compared to the SQP algorithm? Is it better? Worse? Slower? Faster? Does the trajectory go all the way to the goal? If you change the parameters for the cost function by adjusting `Q` and `R` in that file what happens? Play around with it a little bit. Hopefully it will give you a little better intuition for what the math is doing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "trajopt_obj.solve(x0, u0, N, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "q1-taylor-and-ddp": {
     "name": "q1-taylor-and-ddp",
     "points": 8,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
